Fraud Detection in Car Insurance Claims Using Machine Learning

This project aims to detect fraudulent car insurance claims using advanced machine learning techniques and comprehensive data analysis.
The study effectively predicts fraud by leveraging Random Forest, Support Vector Machine (SVM), AdaBoost, and other ensemble models.
Key techniques include feature engineering, statistical testing (Chi-Square and ANOVA), class imbalance handling with SMOTE, and model evaluation using AUC-ROC and F1-score metrics. The project addresses the significant financial impact of fraud on the UK insurance sector, where fraudulent claims cost over £1.1 billion annually.


Skills Demonstrated

This project showcases my ability to perform the following key data science skills:
   • Data Preprocessing: Cleaning, imputing missing values, encoding categorical variables, and scaling features.
   • Exploratory Data Analysis (EDA): Deep investigation into data distributions, fraud patterns, and anomaly detection.
   • Statistical Testing: Applying Chi-Square tests for categorical variables and ANOVA for numerical features to validate significance.
   • Feature Engineering: Creating new features (e.g., ratios, time gaps) to capture hidden fraud patterns.
   • Feature Selection: Using SelectKBest to isolate the most predictive features for model building.
   • Handling Class Imbalance: Implementing SMOTE to balance minority (fraud) and majority classes.
   • Model Development: Building and training machine learning models including Random Forest, AdaBoost, Gradient Boosting, XGBoost, SVM, and k-Nearest Neighbors.
   • Model Evaluation: Assessing models using precision, recall, F1-score, AUC-ROC, and confusion matrices for comprehensive performance analysis.
   • Python Programming: Proficiency with Python and libraries such as pandas, numpy, scikit-learn, imbalanced-learn, matplotlib, seaborn, and XGBoost.
   • Machine Learning Expertise: Applying ensemble learning techniques and imbalanced classification strategies.
   • Analytical Thinking: Drawing meaningful insights from model results to guide future research and practical implementation.


Summary of Findings

The study revealed that the Random Forest model consistently outperformed other techniques, achieving 84.5% accuracy, a fraud class F1-score of 69.3%, and an AUC-ROC of 0.841. AdaBoost demonstrated the highest fraud recall (85.7%), making it highly effective in minimizing missed fraud cases. SVM also provided strong performance, offering a good balance between precision and recall for fraud detection. Application of SMOTE significantly improved all models’ sensitivity to fraudulent claims, confirming the critical importance of handling class imbalance in fraud detection systems.

Overall, ensemble models (Random Forest, AdaBoost, Gradient Boosting) proved far superior to simpler classifiers like Logistic Regression in detecting fraudulent activity within highly imbalanced datasets.
